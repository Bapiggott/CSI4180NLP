# TS2Vec: Towards Universal Representation of Time Series

## Overview
This study (Yue et al., 2022, *NeurIPS*) introduces **TS2Vec**, a universal self-supervised representation learning framework for time series data. The method focuses on learning generalizable embeddings that can be transferred across domains with minimal fine-tuning.

**Key elements:**
- **Training Objective:**
  - Contrastive self-supervised learning applied at multiple temporal resolutions.
  - Aligns embeddings of nearby subsequences while separating distant ones.
- **Architecture:**
  - Temporal encoder with hierarchical context learning.
  - Multi-scale contrastive loss enforces both local and global consistency.
- **Applications:**
  - Time series classification, clustering, and forecasting tasks.
- **Results:**
  - Outperforms prior self-supervised baselines across a wide range of datasets.
  - Achieves strong generalization with limited labeled samples.
- **Contribution:**
  - Provides a foundation for universal time series embeddings, reducing the need for large labeled datasets.

## Relation to Our Project
Our project focuses on multimodal malware detection in encrypted traffic using NLP and vision.  

**Direct connections:**
- TS2Vec shows that self-supervised pretraining on unlabeled time series (e.g., packet metadata sequences) can yield powerful embeddings before supervised fine-tuning.
- Directly relevant for our NLP branch: traffic metadata can be treated as time series for pretraining.
- Helps mitigate data scarcity and imbalance by leveraging unlabeled flows.
- Suggests we can combine pretrained TS2Vec embeddings with CNN/ViT image features for multimodal fusion.

## Possible Extensions
1. **Self-Supervised Pretraining:**  
   - Pretrain TS2Vec on large-scale unlabeled encrypted traffic metadata.  
2. **Multi-Resolution Embeddings:**  
   - Use multi-scale embeddings (local + global) to capture fine-grained anomalies and long-term flow behavior.  
3. **Fusion with Visual Features:**  
   - Combine pretrained TS2Vec embeddings with visual flow images for richer multimodal representation.  
4. **Few-Shot Learning:**  
   - Evaluate performance when only small amounts of labeled malicious flows are available.  
5. **Cross-Dataset Generalization:**  
   - Test pretrained TS2Vec on CIC-IDS and N-BaIoT to assess robustness across domains.  

## Key Takeaways
- Self-supervised representation learning can reduce dependency on labels.  
- TS2Vecâ€™s multi-resolution embeddings align well with sequential flow modeling in encrypted traffic.  
- Pretraining with TS2Vec could significantly improve our NLP sequence branch.  
- Combining TS2Vec embeddings with vision features supports stronger multimodal detection.
